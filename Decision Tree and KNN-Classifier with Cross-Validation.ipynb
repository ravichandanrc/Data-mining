{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7daf2c9f",
   "metadata": {},
   "source": [
    "### Observations from the two implemented Classifiers\n",
    "\n",
    "Using the Iris dataset, K Nearest Neighbor and Decision Tree methods are applied to classify iris species. We generate the classification report and confusion matrix using the scikit-learn package. A classification report includes precision, recall, F1-scores, and support, which represents the number of observations of each class (iris species) along with accuracy, macro average, and weighted average.\n",
    "This confusion matrix provides details such as the number of true positives (TP), the number of true negatives (TN), the number of false positives (FP) (Type 1 error) and the number of false negatives (FN) (Type 2 error). Correct predictions are represented by the diagonal values from top left to bottom right.\n",
    "DT Classifier model trained showed 50 total predictions, of which 46 were correct predictions (TN+TP) and 4 were wrong predictions (FP+FN). The KNN Classifier model trained results in 50 predictions, 44 of which are correct (TN+TP) and 6 of which are wrong (FP+FN). In both the Decision Tree and KNN classifiers, the model predictions of class 0 are fully correct since precision, recall, and F1-score are all 1. DT Classifier's recall is higher than precision for class 2, so fewer FN1 are present than FP1. There are more FN2 than FP2 in class 1 because precision is higher than recall. KNN Classifier shows the same precision and recall.\n",
    "In terms of our model evaluation, KNN Classifier performs better than the Decision Tree Classifier. In terms of evaluating the classifier model, precision and recall are both good metrics. If the scale of type 1 errors (FP) is lower than that of type 2 errors (FN), precision would be the better evaluation metric. It is therefore crucial to understand which evaluation metric to use based on a given scenario in order to evaluate models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b189f5",
   "metadata": {},
   "source": [
    "### Setting up Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f70ee681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "#classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e784a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data and splitting it into two sets\n",
    "X,y = sklearn.datasets.load_iris(return_X_y=True) #loading iris dataset\n",
    "X_trainingData, X_testData, y_trainingData, y_testData = train_test_split(X,y,test_size=0.33, random_state = 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c5ed8",
   "metadata": {},
   "source": [
    "## Decision-Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f8021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Classification Report for Decision Tree Classifier***\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.94      0.89      0.91        18\n",
      "           2       0.90      0.95      0.92        19\n",
      "\n",
      "    accuracy                           0.94        50\n",
      "   macro avg       0.95      0.95      0.95        50\n",
      "weighted avg       0.94      0.94      0.94        50\n",
      "\n",
      "\n",
      "\n",
      "***Confusion Matrix for Decision Tree Classifier***\n",
      "\n",
      "[[13  0  0]\n",
      " [ 0 16  2]\n",
      " [ 0  1 18]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model building and prediction\n",
    "myClassifier= DecisionTreeClassifier()\n",
    "myClassifier.fit(X_trainingData, y_trainingData) #creating the model\n",
    "prediction=myClassifier.predict(X_testData) #applying the decision tree model to testdata using predict function\n",
    "\n",
    "#printing the results\n",
    "print(\"***Classification Report for Decision Tree Classifier***\\n\")\n",
    "print(classification_report(y_testData,prediction))\n",
    "print(\"\\n\")\n",
    "print(\"***Confusion Matrix for Decision Tree Classifier***\\n\")\n",
    "print(confusion_matrix(y_testData, prediction))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a31fd2",
   "metadata": {},
   "source": [
    "## Cross-Validation Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad73d5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         0.93333333 0.93333333 0.86666667\n",
      " 1.         0.86666667 0.93333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "myScores=cross_val_score(DecisionTreeClassifier(),X,y,scoring='accuracy',cv=KFold(n_splits=10))\n",
    "print(myScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b84f6d",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "429311d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Classification Report for KNN Classifier***\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       0.83      0.83      0.83        18\n",
      "           2       0.84      0.84      0.84        19\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.89      0.89      0.89        50\n",
      "weighted avg       0.88      0.88      0.88        50\n",
      "\n",
      "\n",
      "\n",
      "***Confusion Matrix for KNN Classifier***\n",
      "\n",
      "[[13  0  0]\n",
      " [ 0 15  3]\n",
      " [ 0  3 16]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming k(the number of neighbors i.e. n_neighbors)=3\n",
    "myClassifier = KNeighborsClassifier(n_neighbors=3, weights='uniform')\n",
    "\n",
    "# Training or fitting the model with the train data\n",
    "myClassifier.fit(X_trainingData, y_trainingData)\n",
    "\n",
    "# applying the model to test data using predict function\n",
    "prediction = myClassifier.predict(X_testData)\n",
    "\n",
    "#printing the results\n",
    "print(\"***Classification Report for KNN Classifier***\\n\")\n",
    "print(classification_report(y_testData,prediction))\n",
    "print(\"\\n\")\n",
    "print(\"***Confusion Matrix for KNN Classifier***\\n\")\n",
    "print(confusion_matrix(y_testData, prediction))\n",
    "print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
